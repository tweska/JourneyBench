#!/usr/bin/env python3

import pathlib

from datetime import datetime, time, timedelta
from typing import List

from benchmark import Network
from gtfs import GTFS
from gtfs.util import find_busiest_date, generate_date_trip_dict, generate_trip_stop_time_dict
from geo.util import haversine


def gtfs2network(
        gtfs_paths: List[pathlib.Path],
        start: datetime = None, end: datetime = None, days: int = 2,
        include_pathways: bool = False,
        speed_ms: float = 1.25  # 4.5 km/h
) -> Network:
    gtfs: GTFS = GTFS.read(gtfs_paths)

    start = start if start else datetime.combine(find_busiest_date(gtfs), time.min)
    end = end if end else start + (timedelta(days=days) - timedelta(seconds=1))

    print(start, end)

    network: Network = Network(int((end - start).total_seconds()))

    # Register stops
    for gtfs_stop in gtfs.stops:
        network.add_node(gtfs_stop.stop_id, gtfs_stop.stop_lat, gtfs_stop.stop_lon, stop=True)

    # Register trips
    date_trip_dict = generate_date_trip_dict(gtfs)
    trip_stop_time_dict = generate_trip_stop_time_dict(gtfs)

    cur_date = (start - timedelta(days=1)).date()  # include previous day in initial search
    trip_id = 0
    while cur_date <= end.date():
        for trip in date_trip_dict[cur_date]:
            stop_times = [gtfs.stop_times[index] for index in trip_stop_time_dict[trip]]
            stops = [st.stop_id for st in stop_times]
            arrivals = [int(((datetime.combine(cur_date, time.min) + st.arrival_time) - start).total_seconds()) for st in stop_times]
            departures = [int(((datetime.combine(cur_date, time.min) + st.departure_time) - start).total_seconds()) for st in stop_times]
            for i in range(len(stops)-1):
                network.add_conn(
                    trip_id,
                    stops[i],
                    stops[i+1],
                    departures[i],
                    arrivals[i+1],
                )
            trip_id += 1
        cur_date += timedelta(days=1)

    if include_pathways:
        for gtfs_pathway in gtfs.pathways:
            if gtfs_pathway.traversal_time is None:
                if gtfs_pathway.length is None:
                    from_stop = gtfs.stops[gtfs_pathway.from_stop_id]
                    to_stop = gtfs.stops[gtfs_pathway.to_stop_id]
                    gtfs_pathway.length = haversine(from_stop.stop_lat, from_stop.stop_lon, to_stop.stop_lat, to_stop.stop_lon)
                gtfs_pathway.traversal_time = int(round(gtfs_pathway.length / speed_ms))
            network.add_path(gtfs_pathway.from_stop_id, gtfs_pathway.to_stop_id, gtfs_pathway.traversal_time)

    return network


if __name__ == '__main__':
    import argparse
    from geo.poly import parse_poly
    from geo.util import trim_network

    parser = argparse.ArgumentParser(
        prog='parseGTFS',
        description='Parse a network from a GTFS file.',
    )
    parser.add_argument('input', type=pathlib.Path, nargs='+', help='input GTFS file(s)')
    parser.add_argument('output', type=pathlib.Path, help='output Network file')
    parser.add_argument('--date', type=lambda s: datetime.strptime(s, '%Y-%m-%d').date(), required=False,
                        help='first date to parse (ISO 8601 date)')
    parser.add_argument('--days', type=int, default=2, required=False,
                        help='number of days to parse from the first date')
    parser.add_argument('--poly', type=pathlib.Path, required=False,
                        help='exclude data outside given polygon (Osmosis .poly file)')
    parser.add_argument('--paths', action='store_true', help='include paths from pathways.txt')
    parser.add_argument('--speed', type=float, default=4.5, required=False, help='walking speed in km/h')
    args = parser.parse_args()

    network = gtfs2network(
        gtfs_paths=args.input,
        start=datetime.combine(args.date, time.min) if args.date else None,
        days=args.days,
        include_pathways=args.paths,
        speed_ms=args.speed * 1000 / 3600
    )

    if args.poly:
        with open(args.poly, 'r') as file:
            poly = parse_poly(file.readlines(), hull=True)
            network = trim_network(network, poly)
    network.write(args.output)
